% !TEX root = Bachelorarbeit Synthetische Daten.tex
\chapter{Diskussion} \label{ch:discussion} % Textur Learning?

% Einleitung
In diesem Kapitel werden die Ergebnisse dieser Arbeit interpretiert und im Kontext der Forschungsfragen diskutiert. Dabei wird auf die Eignung von DA-Fusion zur Generierung synthetischer Daten sowie auf die Wirksamkeit von Near Out-of-Distribution-Augmentationen im Supervised Contrastive Learning eingegangen.

\section{Eignung von DA-Fusion für die synthetische Datengenerierung} \label{sec:da-fusion-discussion}

% Eigene Evaluierung
Die synthetische Datengenerierung mit DA-Fusion zeigt sich als vielversprechender Ansatz. Die erzeugten Augmentationen wiesen überwiegend eine hohe visuelle Qualität auf. DA-Fusion war in der Lage, die Variation innerhalb der Daten zu erhöhen, ohne dabei die akkurate Darstellung der komplexen Gebrauchszustände zu opfern. An dieser Stelle scheitern viele der herkömmlichen Methoden zur synthetischen Datengenerierung, was für vergleichbare Anwendungsfälle in der industriellen Bildverarbeitung ein Hindernis ist, da sie oft durch ähnlich komplexe und spezifische Objektklassen ausgezeichnet sind. Da vortrainierte generative Modelle meist nicht genügend Vorwissen über diese spezifischen Objektklassen besitzen \parencite{Fan2023scalingsyntheticimages} und meist auch nur wenige Beispiele zum Fine-tuning dieser Modelle zur Verfügung stehen, ist es schwierig, realistische Daten zu generieren.

Herkömmliche Datenaugmentationsmethoden wie Rotation, Skalierung oder Farbveränderungen bieten hingegen nicht ausreichend Variation auf semantischer Ebene, um die Generalisierungsfähigkeit von Modellen zu verbessern. DA-Fusion zeigte hier die Fähigkeit, den Zustand von Objekten (z. B. Abnutzung, Verschmutzung oder Schäden) auf realistische und semantisch sinnvolle Art und Weise zu augmentieren. Es ist daher anzunehmen, dass sich diese Fähigkeit auch auf andere Anwendungsfälle übertragen lässt, bei denen die Variation auf semantischer Ebene entscheidend ist. Der einstellbare Grad der Variation ermöglicht es außerdem, je nach Komplexität des Anwendungsfalls eine Einstellung zu wählen, die den Anforderungen entspricht.

% Metriken
Eine quantitative Analyse der Ergebnisse zeigt ebenfalls, dass DA-Fusion zu einer signifikanten Verbesserung der Modellleistung beitragen kann. Die Steigerung der Top-1-Accuracy von 71.4\% auf 77.5\% verdeutlicht, dass die synthetischen Daten einen positiven Effekt auf die Generalisierungsfähigkeit des Modells haben. Auffällig ist auch die Vergrößerung des Abstands zwischen den Confidence-Werten für In-Distribution (ID) und Out-of-Distribution (OOD) Daten von 0.07 auf 0.11. Diese Verbesserung deutet darauf hin, dass das Modell durch die Verwendung synthetischer Daten in der Lage war, robustere Repräsentationen zu lernen, die eine klarere Trennung zwischen verschiedenen Klassen ermöglichen.

% Visualisierung fehlt
Um den Effekt der synthetischen Daten auf den Repräsentationsraum des Modells tiefer zu verstehen, wäre eine Visualisierung mittels Techniken wie t-SNE \parencite{Vandermaaten2008tsne} oder UMAP \parencite{Mcinnes2020umap} ein interessanter nächster Schritt. Solche Visualisierungen bieten eine niedrigdimensionale Darstellung des Repräsentationsraums, die es ermöglicht, die Verteilung der Klassen zu analysieren. Insbesondere könnten sie aufzeigen, inwieweit die synthetischen Daten den Abstand zwischen den Klassen im Repräsentationsraum vergrößert haben.

Des Weiteren wäre eine visuelle Auswertung durch Saliency Maps, wie in \parencite{Sammani2023visualizingunderstandingcontrastivelearning}, interessant. So könnte untersucht werden, ob durch die Augmentationen weniger Fokus auf die Textur der Objekte gelegt wird und stattdessen mehr auf die Form und Struktur, was für den vorgestellten Anwendungsfall besonders relevant ist.

% Laborbedingungen
Trotz der positiven Ergebnisse muss beachtet werden, dass die verwendeten Validierungsbilder die selben Laborbedingungen abbilden wie die Trainingsbilder. Es bleibt somit die Frage offen, wie gut das Modell auf neue, reale Szenarien generalisieren würde. In realen Anwendungen könnten Faktoren wie Beleuchtungsbedingungen, Kamerawinkel oder andere äußere Einflüsse dazu führen, dass die synthetischen Daten nicht in gleichem Maße zur Generalisierung beitragen wie unter den hier getesteten Bedingungen.

% Rechen- und Zeitaufwand
Ein Nachteil von DA-Fusion ist der Rechen- und Zeitaufwand, der sich aus dem Fine-tuning des Stable Diffusion-Modells mit neuen Text-Embeddings für jede Klasse ergibt. Dabei ist auch die Anpassung der Hyperparameter nicht trivial und erfordert eine sorgfältige Abstimmung, was den Einsatz von DA-Fusion in groß angelegten Anwendungsfällen erschwert.

% Zusammenfassung
Zusammenfassend lässt sich feststellen, dass DA-Fusion eine vielversprechende Methode zur Generierung synthetischer Daten ist. Es bietet nicht nur eine realistische Darstellung von Gebrauchszuständen, sondern kann auch gezielt auf die Anforderungen des jeweiligen Anwendungsfalls abgestimmt werden. Allerdings ist der Rechenaufwand und die Abstimmung des Fine-Tunings nicht zu unterschätzen, und zukünftige Arbeiten könnten sich darauf konzentrieren, hier effizientere Verfahren anzuwenden.

Eine mögliche Weiterentwicklung für die Datenaugmentaion mit DA-Fusion in Bezug auf den untersuchten Anwendungsfall wäre die Begrenzung der Augmentation auf bestimmte Regionen des Objektes. Während in den durchgeführten Experimenten bereits Segmentierungsmasken verwendet wurden, um die Bilder auf das Objekt zu beschränken, könnten weitere, kleinere Masken verwendet werden, um nur bestimmte Bereiche des Objektes zu augmentieren. Womöglich könnten so auch stärkere Augmentationen durchgeführt werden, ohne die gesamte Struktur des Objektes zu verändern.

% DA-Fusion für Multi-View Augmentation im CL?
Es eröffnet sich außerdem eine spannende Forschungslücke durch die Anwendung von DA-Fusion im Contrastive Learning. DA-Fusion wurde primär als Methode zur Datenaugmentation entwickelt. Es wäre deshalb interessant zu untersuchen, wie sich das Lernen der Repräsentationen verhält, wenn DA-Fusion direkt zur Generierung der zwei unterschiedlichen Ansichten eines Bildes verwendet wird, anstatt die generierten Augmentationen mit den originalen Trainingsbildern zu mischen.

\section{Wirksamkeit von Near Out-of-Distribution-Augmentationen im Supervised Contrastive Learning} \label{sec:ood-discussion}

% Schlechtere Ergebnisse
Während die ID-Augmentationen eine Verbesserung der Klassifikationsleistung bewirkten, zeigte sich ein gegenteiliger Effekt bei den Near OOD-Augmentationen. Die Top-1 Accuracy sank von 77.5\% auf 75.3\%, und auch die Confidence-Werte (ID und OOD) verschlechterten sich signifikant.

Die Ergebnisse könnten auf mehrere Faktoren zurückzuführen sein: 1) die Qualität der synthetisch erzeugten OOD-Daten, 2) die Komprimierung der Repräsentationen der ID-Daten ,und 3) die Sampling-Strategie für die Near OOD-Augmentationen im Supervised Contrastive Learning.

% 1) Qualität der synthetisch erzeugten OOD-Daten
Ein wesentlicher Faktor, der zu den schlechteren Ergebnissen beigetragen haben könnte, ist die Qualität der synthetisch erzeugten Near OOD-Daten. Es zeigte sich, dass viele der erzeugten OOD-Daten Artefakte aufwiesen oder keinerlei Verbindung mehr vom ursprünglichen Konzept der Klasse hatten. In diesen Fällen fielen die synthetischen Daten nicht mehr in die Kategorie "Near OOD", sondern waren zu weit von den ID-Daten entfernt, um als sinnvolle Hard Negatives zu fungieren. Diese Diskrepanz führte dazu, dass das Modell die Near OOD-Daten möglicherweise als einfach zu unterscheidende OOD-Daten interpretierte, anstatt feinere Unterschiede zwischen ID-Klassen zu lernen.

% 2) Komprimierung der Repräsentationen der ID-Daten
Die Verwendung dieser ungenauen OOD-Daten könnte außerdem die Repräsentationen der ID-Daten negativ beeinflusst haben. Falls das Modell nur zwischen ID und OOD-Daten unterscheidet, könnte das dazu führen, dass die Repräsentationen der ID-Daten "in die Mitte" des Repräsentationsraums komprimiert werden. Das würde es für das Modell schwieriger machen, zwischen den Klassen zu unterscheiden. Auch hier würde eine Visualisierung des Repräsentationsraums helfen, um solche Verzerrungen zu erkennen.

% 3) Sampling-Strategie & Implementierung
Schließlich könnte auch die Sampling-Strategie für die Near OOD-Augmentationen und dessen Implementierung im Supervised Contrastive Learning eine Rolle gespielt haben. Die richtige Anpassung des Trainingsablaufs und der Verlustfunktion, um Near OOD-Daten als Hard Negatives zu nutzen, erwies sich als komplex. Im gewählten Ansatz wurden sowohl ID- als auch OOD-Augmentationen unter die normalen Trainingsbilder gemischt. Die Maskierung der kontrastiven Paare stellte zwar sicher, dass nur die ID-Augmentationen als positiv-Beispiele und die Near OOD-Augmentationen als negativ-Beispiele verwendet wurden, jedoch unterschied sich somit auch die effektive Anzahl der verwendeten Paare für jedes Batch. Das liegt daran, dass für jedes Ankerbeispiel nur bestimmte OOD-Beispiele als Hard Negatives ausgewählt wurden. Dies könnte zu einer Verzerrung der Loss-Funktion geführt haben und sich auf unerwünschte Weise auf das Training ausgewirkt haben.

% Verbesserungsmöglichkeiten
Um die Wirksamkeit von Near OOD-Augmentationen zu verbessern, könnten verschiedene Ansätze verfolgt werden. Zunächst sollte die Qualität der synthetisch erzeugten OOD-Daten optimiert werden, indem beispielsweise andere Augmentationsstärken ausprobiert werden. Auch das Fine-tuning der Text-Embeddings, aus denen sowohl die ID- als auch die OOD-Daten generiert werden, könnte mit einer anderen Methode als Textual Inversion durchgeführt werden. Womöglich könnte ein besseres Lernen der Konzepte zu Augmentationen führen, die näher an den ID-Daten liegen und insgesamt realistischer sind.

Zum anderen könnte die Implementierung der Near OOD-Augmentationen im Supervised Contrastive Learning überdacht werden. Eine Möglichkeit wäre eine Sampling-Strategie für Hard Negatives wie in \parencite{Jiang2024supconhardnegatives}, bei der nur negativ-Beispiele aus einer gewissen Nähe im Repräsentationsraum ausgewählt werden. Das könnte allerdings auch dazu führen, dass die OOD-Daten gar nicht mehr ausgewählt werden, wenn sie zu weit von den ID-Daten entfernt sind.

% Zusammenfassung
Zusammenfassend lässt sich feststellen, dass die Near OOD-Augmentationen im Supervised Contrastive Learning nicht die erwarteten Verbesserungen gebracht haben. Die Ergebnisse zeigen, dass sowohl die Qualität der synthetischen OOD-Daten als auch die Implementierung der Near OOD-Augmentationen überdacht und optimiert werden müssen. Besonders die Generierung von semantisch näheren OOD-Daten und die Vermeidung von Verzerrungen im Repräsentationsraum der ID-Daten könnten entscheidend sein. Die grundsätzlich Frage, ob auch mangelhafte synthetische Daten dazu beitragen können, dass die Repräsentation von ID-Daten verbessert wird, bleibt vorerst offen.