\chapter{Methodisches Vorgehen}

In diesem Kapitel wird das methodische Vorgehen der Arbeit beschrieben. Es wird auf die Forschungsfragen und Hypothesen eingegangen, der verwendete Datensatz vorgestellt und die Implementierung der Modelle DA-Fusion und Supervised Contrastive Learning erläutert. Anschließend wird die synthetische Datengenerierung mit DA-Fusion und die Trainings- und Testdurchläufe mit Supervised Contrastive Learning beschrieben. Abschließend werden die Evaluationsmethoden und Metriken vorgestellt, die zur Analyse der Ergebnisse verwendet werden.

\section{Forschungsfragen und Hypothesen}

XXX Die Forschungsarbeit beschäftigt sich mit der Frage, ob synthetische Daten, die mit dem Modell DA-Fusion generiert wurden, die Generalisierung und Robustheit von Modellen verbessern können, die mit Supervised Contrastive Learning trainiert wurden. Dazu werden die synthetischen Daten in das Training des Modells integriert und die Auswirkungen auf die Performance des Modells untersucht. Insbesondere wird die Möglichkeit untersucht, starke Augmentationen als Out-of-Distribution-Beispiele im Training zu verwenden, indem sie ausschließlich als negative Beispiele für das Contrastive Learning dienen.

\begin{itemize}[]
	\item Kann DA-Fusion für den Datensatz des Fraunhofer-IPK überzeugende synthetische Daten generieren?
	\item Eignet sich DA-Fusion, um sowohl positiv- als auch negativ-Beispiele für das Contrastive Learning zu generieren?
	\item Kann der beschriebene Ansatz eine bessere Generalisierung und Robustheit erzielen als ohne synthetische Daten bzw. als eine naive Verwendung der synthetischen Daten ohne Contrastive Learning?
\end{itemize}

\section{Datensatz}

...

\subsection{EIBA}

Grundlage der Forschungsarbeit ist ein am Fraunhofer-IPK entstandener Datensatz von Gebrauchsgegenständen, darunter hauptsächlich Autoteile und Komponenten. Er wurde im Rahmen des Projekts “Sensorische Erfassung, automatisierte Identifikation und Bewertung von Altteilen anhand von Produktdaten sowie Informationen über bisherige Lieferungen” (EIBA) erstellt, das von 2019 bis 2023 lief und von der Circular Economy Solutions GmbH koordiniert und in Kooperation mit der Technischen Universität Berlin und der deutschen Akademie der Technikwissenschaften durchgeführt wurde. \cite{}

Der Datensatz ist multimodal, d.h. er besteht aus verschiedenen Datenquellen, die unterschiedliche Informationen über die Gegenstände enthalten. Neben herkömmlichen RGB-Bildern aus verschiedenen Perpektiven und weiteren Bilddaten, wie z.B. Objektmasken, gibt es auch Metadaten, etwa das Gewicht, oder Beschreibungen der Objekte in natürlicher Sprache durch verschiedene Stichwörter ("CarComponent", "cylinder", "rusty", usw.).

- Klassen und Anzahl der Bilder insgesamt
- Verteilung der Klassen
- Beispielbilder, -masken, -metadaten

\subsection{Teildatensatz}

Um die Rechenzeit zu reduzieren und die Experimente auf eine bestimmte Objektkategorie zu beschränken, wurde ein Teildatensatz des EIBA-Datensatzes verwendet. Dabei wurden zufällig 20 Klassen aus der super class "CarComponent" ausgewählt. Es wurden außerdem nur die RGB-Bilder verwendet, allerdings kommen auch die Objektmasken im Pre-Processing der Daten zum Einsatz. ...

- Klassen und Anzahl der Bilder in Teildatensatz

\subsection{Vorverarbeitung}

- Verwendung der Objektmasken, um die Bilder zu croppen
	- Bounding Box
	- Quadratischer Output
	- Weniger Aufmerksamkeit auf gleichbleibenden Hintergrund
- Verschiedene "klassische" Augmentationen
	- Rotation
	- ColorJitter
- Normalisierung der Bilder

\section{Implementierung}

- Arbeitsumgebung, Rechner-Zugang, etc.
- Programmiersprache, Bibliotheken, etc.
- DA-Fusion
	- Bestehende Implementierung verstehen
	- Klasse zum Laden des EIBA-Teildatensatzes
		- Masken-cropping
		- Masken für Augmentation
	- Workflow-Anpassungen für Input/Output
- Supervised Contrastive Learning
	- Klasse zum Laden des EIBA-Teildatensatzes und der Augmentationen
	- Workflow-Anpassungen für Input/Output (wie DA-Fusion)
	- Parameter für Konfiguration der Verwendung der Augmentationen
	- Integration von OOD-Augmentationen im Contrastive Learning
	- Metriken für Evaluation
		- Accuracy
		- ID- und OOD-Confidence

Für die Vorbereitung der in dieser Arbeit durchgeführten Experimente konnte sich größtenteils auf die Implementierung von DA-Fusion und Supervised Contrastive Learning aus den Quellen ... und ... gestützt werden. Beide Implementierungen sind in Python geschrieben und verwenden die Bibliothek PyTorch. ...

Dennoch mussten einige Anpassungen vorgenommen werden, um die Modelle auf den EIBA-Teildatensatz anzuwenden, und um die synthetischen Augmentationen aus DA-Fusion im Supervised Contrastive Learning zu verwenden.

\subsection{DA-Fusion}

In ...'s Implementierung von DA-Fusion wird zunächst mit Textual Inversion ein vortrainiertes Stable Diffusion-Modell fine-tuned, indem ein neuer Token für jede Klasse im Datensatz erlernt wird. Um anschließend die Augmentationen zu generieren, werden die Bilder des Datensatzes genommen, Rauschen hinzugefügt und unter Konditionierung auf den entsprechenden Token wiederhergestellt. Je nachdem, wie viel Rauschen hinzugefügt wurde, entstehen so mehr oder weniger stark veränderte Bilder, die als synthetische Daten verwendet werden können.

...

Die Implementierung von DA-Fusion kann weitgehend unverändert angewendet werden, um synthetische Daten für den EIBA-Teildatensatz zu generieren. Es muss lediglich eine eigene Klasse für den Datensatz erstellt werden, die die Bilder und Masken aus dem EIBA-Datensatz lädt und die Token für die Klassen bereitstellt. ...

\subsection{Supervised Contrastive Learning}

...'s Implementierung von Supervised Contrastive Learning beinhaltet drei Trainings-Skripte; eines für das Pre-Training der latenten Repräsentationen unter Verwendung der Supervised Contrastive Loss-Funktion, eines für die lineare Klassifikation der Repräsentationen und eines zum Training eines klassischen Klassifikator-Modells mit Cross Entropy Loss (zum Vergleich).

...

Auch hier muss eine eigene Klasse für den EIBA-Teildatensatz erstellt werden, die die Bilder und Masken lädt und die synthetischen Daten von DA-Fusion bereitstellt. Die Klasse muss nun auch Parameter bereitstellen, die die Verwendung der synthetischen Daten steuern, z.B. ob keine Augmentationen, ausschließlich positiv-Beispiele oder auch negativ-Beispiele verwendet werden sollen. ...

Metriken ...

\section{Synthetische Datengenerierung mit DA-Fusion}

- Synthetische Datengenerierung mit DA-Fusion
	- ID-Augmentationen, OOD-Augmentationen
	- Trial and Error, um Parameter zu bestimmen, Validierung ist schwierig

\section{Trainings- und Testdurchläufe mit Supervised Contrastive Learning}

- Trainings- und Testdurchläufe mit Supervised Contrastive Learning
	- Nur reale Daten
	- Mit ID-Augmentationen
	- Mit ID-Augmentationen (und Contrastive Pre-Training mit OOD-Augmentationen)
- Evtl. klassischer Klassifikator mit Cross-Entropy Loss

\section{Evaluationsmethoden und Metriken}

- Synthetische Daten
- Klassifikation
	- Accuracy
	- ID- und OOD-Confidence

\section{Analyse der Ergebnisse}

...